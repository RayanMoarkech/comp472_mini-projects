3.8)
For this step, the following English pretrained embedding models where used:
- FastText
- GloVe

About FastText:

FastText is another word embedding method that is an extension of the Word2Vec model.
fastText represents each word as an n-gram of characters, instead of learning vectors for words directly.
This helps capture the meaning of shorter words and allows the embeddings to understand suffixes and prefixes.
FastText works well with rare words. So even if a word was not seen during training, it can be broken down into n-grams
to get its embeddings.

About GloVe:

GloVe is short for Global Vector. The model produces a vector space with meaningful substructure.
It is built on global matrix factorization and local context window.

The performance results are as the following:

For emotions:

    Model               Precision           Recall

Base MLP Word2Vec         0.40               0.42
Base MLP FastText         0.39               0.42
Base MLP GloVe            0.38               0.39
Top MLP Word2Vec          0.26               0.39
Top MLP FastText          0.22               0.37
Top MLP GloVe             0.22               0.36


For sentiments:

    Model               Precision           Recall

Base MLP Word2Vec         0.53               0.54
Base MLP FastText         0.55               0.55
Base MLP GloVe            0.51               0.51
Top MLP Word2Vec          0.52               0.52
Top MLP FastText          0.52               0.53
Top MLP GloVe             0.49               0.49


It can be noticed that the precision and recall of the different embeddings are really close to each other for each
classification and each model. These results are expected since fastText and GloVe are an extension of Word2Vec.
Therefore, they should have a similar result. It can be also noticed that there is a slight difference, which can help
in the ranking: (1) fastText, (2) Word2Vec, (3) GloVe. As noted in the about section, fastText uses another way to
analyse the output. It does not use vectors like Word2Vec and GloVe, which make it faster and more accurate.
In addition, Word2Vec and GloVe both fail to provide any vector representation for words that are not in
the model dictionary. This is a huge advantage of this method.